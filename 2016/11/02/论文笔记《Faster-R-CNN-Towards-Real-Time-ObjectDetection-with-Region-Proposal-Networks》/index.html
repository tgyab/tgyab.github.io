<!DOCTYPE html>
<html>
  <!-- Html Head Tag-->
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="Yajing Guo">
  <!-- Open Graph Data -->
  <meta property="og:title" content="论文笔记《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》"/>
  <meta property="og:description" content="" />
  <meta property="og:site_name" content="Yajing Guo&#39;s Blog"/>
  <meta property="og:type" content="article" />
  <meta property="og:image" content="http://yoursite.comundefined"/>
  
    <link rel="alternate" href="/atom.xml" title="Yajing Guo&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  

  <!-- Site Title -->
  <title>Yajing Guo's Blog</title>

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/css/bootstrap.min.css">
  <!-- Custom CSS -->
  
  <link rel="stylesheet" href="/css/style.light.css">

  <!-- Google Analytics -->
  

</head>

  <body>
    <!-- Page Header -->


<header class="site-header header-background" style="background-image: url(/img/default-banner-light.jpg)">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="page-title with-background-image">
          <p class="title">论文笔记《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》</p>
          <p class="subtitle"></p>
        </div>
        <div class="site-menu with-background-image">
          <ul>
            
              <li>
                <a href="/">
                  
                  Home
                  
                </a>
              </li>
            
              <li>
                <a href="/archives">
                  
                  Archives
                  
                </a>
              </li>
            
              <li>
                <a href="https://github.com/tgyab">
                  
                  Github
                  
                </a>
              </li>
            
              <li>
                <a href="mailto:649960532@qq.com">
                  
                  Email
                  
                </a>
              </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</header>


<article>
  <div class="container typo">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <div class="post-info text-muted">
          
            <!-- Author -->
            <span class="author info">By Yajing Guo</span>
          
          <!-- Date -->
          <span class="date-time info">On
            <span class="date">2016-11-02</span>
            <span class="time">12:53:40</span>
          </span>
          
          <!--  Categories  -->
            <span class="categories info">Under 

<a href="/categories/论文笔记/">论文笔记</a>
</span>
          
        </div>
        <!-- Tags -->
        
          <div class="post-tags text-muted">
            Tags: 

<a class="tag" href="/tags/Object-Detection-Region-Proposal-Convolutional-Neural-Network/">#Object Detection, Region Proposal, Convolutional Neural Network</a>


          </div>
        
        <!-- Post Main Content -->
        <div class="post-content">
          <p>　　目前R-CNN系列方法中的最优方案，完全实现了端到端的训练与测试。</p>
<a id="more"></a>
<p>论文下载:<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="external">https://arxiv.org/abs/1506.01497</a></p>
<p>代码网址：<a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></p>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>　　自2012年深度学习再次变为热点后，目标检测领域的state-of-the-art几乎全部基于卷积神经网络（CNN），主要包括R-CNN系列方法以及回归方法。其中，R-CNN系列方法的发展主要经历了R-CNN，SPPnet，Fast R-CNN，以及本文的Faster R-CNN。作者是微软的Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun，发表在2016CVPR上，目前谷歌学术引用次数397。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>　　虽然SPPnet和Fast R-CNN已经在很大程度上减少了运行时间，但是提取region proposal的计算量依然是检测的瓶颈。因此论文作者提出了RPN网络（Region Proposal Network），将提取region proposal的任务在网络中实现，RPN是全卷积网络，能够同时预测目标边框并对每个位置进行打分。通过共享卷积特征将RPN和Fast R-CNN融合起来，可以进行端到端的训练和测试。</p>
<h1 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h1><p>　　尽管R-CNN方法利用了GPU加速运算，但是提取region proposal的过程还是用CPU实现，这大大拖慢了整个检测的进程，例如：使用Selective Search方法提取region proposal每幅图像需要2s，EdgeBoxes方法虽然在proposal的质量和速度上达到更好的平衡，但是每幅图像依然需要0.2s，远远达不到目标检测对实时的要求。</p>
<p>　　因此作者提出了RPN（Region Proposal Network）网络，能够和检测框架（如Fast R-CNN）共享卷积特征，通过共享计算，每幅图像仅需要10ms。RPN是全卷积网络，能够同时预测目标边框并对每个位置进行打分。RPN网络提出了“anchor”boxes（Figure1，c）来解决不同尺度以及不同宽长比的问题，区别于金字塔图像（Figure1，a）和金字塔滤波器（Figure1，b）　</p>
<p><img src="http://ww2.sinaimg.cn/large/9c9fe229jw1f9exre6yn3j20p707t420.jpg" alt=""></p>
<h1 id="二、Faster-R-CNN"><a href="#二、Faster-R-CNN" class="headerlink" title="二、Faster R-CNN"></a>二、Faster R-CNN</h1><p>　　Faster R-CNN检测框架主要由两部分构成，即提出region proposal的RPN网络和进行检测的Fast R-CNN模块。整个网络就是一个注意力机制（‘attention’ mechanism），RPN是整个网络的“attention”部分，告诉Fast R-CNN部分应该看哪。</p>
<p> 　　　　　　　　　　　　　<img src="http://ww1.sinaimg.cn/large/9c9fe229jw1f9ey8un6i3j20cg0efdhx.jpg" alt=""></p>
<h2 id="2-1-Region-Proposal-Networks（RPN）"><a href="#2-1-Region-Proposal-Networks（RPN）" class="headerlink" title="2.1 Region Proposal Networks（RPN）"></a>2.1 Region Proposal Networks（RPN）</h2><p>　　RPNs 从任意尺寸的图片中得到一系列带有 objectness score 的 object proposals。具体做法是：使用一个小网络在最后一层卷积得到的特征图上滑动，将特征图上n×n的窗口作为输入，每个窗口都映射成为一个低维向量（对于ZF网络来说是256维，对于VGG16来说是512维）。这个低维向量又被送到两个全连接层——一个box回归层（reg），一个box分类层（cls），论文中使用的n=3。</p>
<p><img src="http://ww4.sinaimg.cn/large/9c9fe229jw1f9ez0a9mi1j20pc09vwj2.jpg" alt=""></p>
<h3 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h3><p>　　对于每一个n×n的窗口，同时预测k个proposal，，所以回归层输出为4k，分类层输出2k来表示是目标或者不是目标的概率（实际操作中，作者将cls层作为一个两类的softmax层，也可以用一个logistic regression输出k个得分）。实际操作中使用3种尺度以及3种宽长比，因此k=9，即每个位置对应9个anchor boxes。对于大小为W×Ｈ的特征图，共有WHk个anchor boxes。</p>
<p>　　本文的平移不变性，是指以窗口中心进行多个尺度、宽高比的采样。如上图右边，文中使用了3种尺度和3种宽长比 （1:1,1:2,2:1）, 产生了 k = 9 个anchor boxes。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>　　正样本：a.与ground truth的IoU值最高的anchor；b.IoU&gt;0.7的anchors；负样本：IoU&lt;0.3的anchors。</p>
<p>　　损失函数定义为：</p>
<p>　　　　　　　　　　　<img src="http://img.blog.csdn.net/20160513161402505" alt="img"></p>
<p>　　其中，i为一个anchor在一个mini-batch中的下标，pi是anchor i为一个object的预测可能性。如果这个anchor是positive的，则ground-truth标签pi<em>为1，否则为0。ti表示预测bounding box的4个参数化坐标，ti</em>是这个positive anchor对应的ground-truth  box。分类损失Lcls是一个二值分类器（是目标或者不是）的softmax loss。回归损失<img src="http://img.blog.csdn.net/20160513162701740" alt="img">，其中R是Fast R-CNN中定义的robust loss function (smooth L1)。pi<em>Lreg表示回归损失只有在positive anchor（pi</em>=1)的时候才会被激活。cls与reg层的输出分别包含{pi}和{ti}。</p>
<p>　　平衡参数λ来平衡Ncls和Nreg。cls term标准化为mini-batch的大小（Ncls=256），reg term标准化为anchor位置的数目（Nreg~2400），默认λ=10，使得cls term和reg term权重大致相等。</p>
<p>　　对于bounding box的回归，应用了以下4个坐标的参数化：</p>
<p>　　　　　　　　　　　<img src="http://ww3.sinaimg.cn/large/9c9fe229jw1f9fu0o9smgj209003fwf0.jpg" alt=""></p>
<p>　　x、y、w、h表示box中心的坐标以及它的宽度和高度。变量x、xa和x*分别针对于预测的box、anchor box 和ground-truth box（y、w、h也是一样的）。可以认为是从一个anchor box到一个附近的ground-truth box的回归。</p>
<h3 id="训练-RPNs"><a href="#训练-RPNs" class="headerlink" title="训练 RPNs"></a>训练 RPNs</h3><p> 　　利用反向传播和随机梯度下降（SGD）来训练RPN。使用“image-centric”采样策略来训练这个网络。每个mini-batch来自于一张图片，包含许多positive anchor和negative anchor。如果对所有anchor的损失函数进行优化，会偏袒negative样本。因此，在一张图片中随机取样256个anchor来计算一个mini-batch的损失函数，取样的positive anchor和negative anchor的比例在1:1之上。若一张图像没有128个positive样本，则用negative样本来补充。</p>
<p>　　使用标准偏差为0.01的零均值高斯分布来对新增的层进行随机初始化，其余使用ImageNet的模型来进行初始化。使用0.001的学习率来学习60k个mini-batches，以及0.0001的学习率来学习后面PASCAL VOC数据集的20k个mini-batch。momentum=0.9，weight-decay=0.0005，使用了Caffe框架。</p>
<h2 id="2-2-RPN和Fast-R-CNN共享特征"><a href="#2-2-RPN和Fast-R-CNN共享特征" class="headerlink" title="2.2 RPN和Fast R-CNN共享特征"></a>2.2 RPN和Fast R-CNN共享特征</h2><p>　　作者提出了3种训练策略：</p>
<p>（1）交替训练。先训练RPN，利用产生proposal的训练Fast R-CNN，微调好的Fast R-CNN又用来初始化RPN，然后迭代这个过程。本文使用该方法。</p>
<p>（2）近似联合训练。训练时将RPN和Fast R-CNN融合成一个网络，每一次SGD迭代中，前向传播产生region proposal，训练Fast R-CNN时将产生的region proposal视为固定的、预先计算的proposal。反向传播时，对于共享的层，将RPN和Fast R-CNN各自产生的损失组合起来。这种方式实行起来简单，但是忽视了proposal boxes坐标的倒数，所以是近似的。</p>
<p>（3）非近似联合训练。正如上述讨论，RPN预测的bounding boxes也是输入的函数。Fast R-CNN的RoI池化层以卷积特征和预测的bounding boxes作为输入，所以理论上反向传播也应该包括box坐标的梯度，在近似联合训练中这点被忽略了。所以在非近似联合训练中，RoI池化层对box坐标是可微的，这种解决方案在另一篇论文中被提出，即“RoI wraping”层。（J. Dai, K. He, and J. Sun, “Instance-aware semantic segmentation via multi-task network cascades,” arXiv:1512.04412, 2015. ）</p>
<p>　　本文采用四部交替训练：</p>
<p>step1：使用3.1.3节的方法来训练RPN。使用提前训练好的ImageNet模型来初始化，然后对region proposal task进行微调。</p>
<p>step2：使用step1中得到的proposal和Fast R-CNN来训练一个单独的detector network。这个detector network也是使用提前训练好的ImageNet模型来初始化。到这个时候两个网络还没有共享卷积层。</p>
<p>step3：我们step2中训练好的detector network来初始化RPN，然后训练。这里训练的使用固定共享卷积网络，只微调RPN部分的网络层。这个时候两个网络共享卷积层。</p>
<p>step4：保持共享卷积层固定，只微调Fast R-CNN部分的网络层。</p>
<p>　　这样，两个网络共享了相同的网络层，形成了一个统一的网络。</p>
<h2 id="2-3-实现细节"><a href="#2-3-实现细节" class="headerlink" title="2.3 实现细节"></a>2.3 实现细节</h2><p>　　使用单一尺度的图片来对region proposal 和目标检测网络进行训练和测试。归一化图片使得它的较短边s=600像素。对于anchor，使用三种scale，box的面积分别为128<em>128、256</em>256、和512*512，高宽比分别为1:1、1:2和2:1。这些参数不需要针对某一数据集进行谨慎选择（作者在下一章中对他们的影响进行了切除实验）。文中的方法不需要一个图像金字塔或者filter金字塔来预测多尺度区域，节省了许多运行时间。</p>
<p>　　穿过图片边界的anchor boxes应该小心处理。在训练的时候，忽略所有穿过边界的anchors。对一张1000<em>60的图像，大概总共有20000（≈60</em>40*9）个anchor。忽略穿过边界的anchor后，每张图片大概有6000个anchor来进行训练。然而，在测试的时候，将全卷积RPN应用到整张图片中。这有可能产生穿过边界的proposal boxes，将其作为图片边界减掉。</p>
<p>　　一些RPN proposal彼此高度重合。为了减少冗余，在它们的cls  score的基础上在proposal区域应用非极大抑制（non-maximum suppression，NMS）。NMS的IoU阈值固定为0.7，使得每张图片留下大概2000个proposal region。NMS并未降低最终的检测准确率。然后，使用2000个RPN proposal来训练Fast R-CNN，但是在测试的时候评估不同数目的proposal。</p>
<h1 id="三、实验结果"><a href="#三、实验结果" class="headerlink" title="三、实验结果"></a>三、实验结果</h1><p>　　之后补充。</p>

        </div>
      </div>
    </div>
  </div>
</article>



    <!-- Footer -->
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <p class="copyright text-muted">
          Theme By <a target="_blank" href="https://github.com/levblanc">Levblanc.</a>
          Inspired By <a target="_blank" href="https://github.com/klugjo/hexo-theme-clean-blog">Clean Blog.</a>
        <p class="copyright text-muted">
          Powered By <a target="_blank" href="https://hexo.io/">Hexo.</a>
        </p>
      </div>
    </div>
  </div>
</footer>


    <!-- After Footer Scripts -->
<script src="/js/highlight.pack.js"></script>
<script>
  document.addEventListener("DOMContentLoaded", function(event) {
    var codeBlocks = Array.prototype.slice.call(document.getElementsByTagName('pre'))
    codeBlocks.forEach(function(block, index) {
      hljs.highlightBlock(block);
    });
  });
</script>

  </body>
</html>

